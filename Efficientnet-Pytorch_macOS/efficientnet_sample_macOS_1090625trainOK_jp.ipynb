{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load efficientnet_sample_macOS_1090625trainOK.py\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "#from efficientnet.model import EfficientNet\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# some parameters\n",
    "use_gpu = torch.cuda.is_available()\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "data_dir = 'OxFlower17_from Baidu'\n",
    "batch_size = 4\n",
    "lr = 0.1\n",
    "momentum = 0.9\n",
    "num_epochs = 60\n",
    "input_size = 224\n",
    "class_num = 17\n",
    "net_name = 'efficientnet-b0'\n",
    "\n",
    "\n",
    "\n",
    "def loaddata(data_dir, batch_size, set_name, shuffle):\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.CenterCrop(input_size),\n",
    "            transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'test': transforms.Compose([\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.CenterCrop(input_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n",
    "\n",
    "    image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in [set_name]}\n",
    "    # num_workers=0 if CPU else =1\n",
    "    dataset_loaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    shuffle=shuffle, num_workers=1) for x in [set_name]}\n",
    "    data_set_sizes = len(image_datasets[set_name])\n",
    "    return dataset_loaders, data_set_sizes\n",
    "\n",
    "\n",
    "def train_model(model_ft, criterion, optimizer, lr_scheduler, num_epochs=10):\n",
    "    train_loss = []\n",
    "    loss_all = []    #109.6.19 add, ref:https://blog.csdn.net/Whisper_lg/article/details/106567721\n",
    "    acc_all = []     #109.6.19 add, ref:https://blog.csdn.net/Whisper_lg/article/details/106567721\n",
    "    since = time.time()\n",
    "    best_model_wts = model_ft.state_dict()\n",
    "    best_acc = 0.0\n",
    "    model_ft.train(True)\n",
    "    for epoch in range(num_epochs):\n",
    "        dset_loaders, dset_sizes = loaddata(data_dir=data_dir, batch_size=batch_size, set_name='train', shuffle=True)\n",
    "        print('Data Size', dset_sizes)\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        optimizer = lr_scheduler(optimizer, epoch)\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        count = 0\n",
    "\n",
    "        for data in dset_loaders['train']:\n",
    "            inputs, labels = data\n",
    "            labels = torch.squeeze(labels.type(torch.LongTensor))\n",
    "            if use_gpu:\n",
    "                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "            else:\n",
    "                inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "            outputs = model_ft(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            count += 1\n",
    "            if count % 30 == 0 or outputs.size()[0] < batch_size:\n",
    "                print('Epoch:{}: loss:{:.3f}'.format(epoch, loss.item()))\n",
    "                train_loss.append(loss.item())\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / dset_sizes\n",
    "        epoch_acc = running_corrects.double() / dset_sizes\n",
    "        loss_all.append(int(epoch_loss*100))               #109.6.19 add, ref:https://blog.csdn.net/Whisper_lg/article/details/106567721\n",
    "        acc_all.append(int(epoch_acc*100))                 #109.6.19 add, ref:https://blog.csdn.net/Whisper_lg/article/details/106567721\n",
    "\n",
    "        print('Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "            epoch_loss, epoch_acc))\n",
    "\n",
    "        if epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model_wts = model_ft.state_dict()\n",
    "        if epoch_acc > 0.999:\n",
    "            break\n",
    "\n",
    "    # save best model\n",
    "    save_dir = data_dir + '/model'\n",
    "    model_ft.load_state_dict(best_model_wts)\n",
    "    model_out_path = save_dir + \"/\" + net_name + 'pth'\n",
    "    torch.save(model_ft, model_out_path)\n",
    "\n",
    "    # ---------109.6.19 add, ref:https://blog.csdn.net/Whisper_lg/article/details/106567721\n",
    "    # plot the figure of acc and loss\n",
    "    x1 = list(range(len(acc_all)))\n",
    "    x2 = list(range(len(loss_all)))\n",
    "    y1 = acc_all\n",
    "    y2 = loss_all\n",
    "    plt.subplot(2, 1, 1)\n",
    "    # plt.plot(x1, y1, 'o-',color='r')\n",
    "    plt.plot(x1, y1, 'o-', label=\"Train_Accuracy\")\n",
    "    plt.title('train acc vs. iter')\n",
    "    plt.ylabel('train accuracy')\n",
    "    plt.legend(loc='best')\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(x2, y2, '.-', label=\"Train_Loss\")\n",
    "    plt.xlabel('train loss vs. iter')\n",
    "    plt.ylabel('train loss')\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig(save_dir + \"/\"+\"acc_loss.png\")\n",
    "    plt.show()\n",
    "    # -------------------------------------------------------------------------------------\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    return train_loss, best_model_wts\n",
    "\n",
    "\n",
    "def test_model(model, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    cont = 0\n",
    "    outPre = []\n",
    "    outLabel = []\n",
    "    dset_loaders, dset_sizes = loaddata(data_dir=data_dir, batch_size=16, set_name='test', shuffle=False)\n",
    "    for data in dset_loaders['test']:\n",
    "        inputs, labels = data\n",
    "        labels = torch.squeeze(labels.type(torch.LongTensor))\n",
    "        inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        if cont == 0:\n",
    "            outPre = outputs.data.cpu()\n",
    "            outLabel = labels.data.cpu()\n",
    "        else:\n",
    "            outPre = torch.cat((outPre, outputs.data.cpu()), 0)\n",
    "            outLabel = torch.cat((outLabel, labels.data.cpu()), 0)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        cont += 1\n",
    "    print('Loss: {:.4f} Acc: {:.4f}'.format(running_loss / dset_sizes,\n",
    "                                            running_corrects.double() / dset_sizes))\n",
    "\n",
    "\n",
    "def exp_lr_scheduler(optimizer, epoch, init_lr=0.1, lr_decay_epoch=10):\n",
    "    \"\"\"Decay learning rate by a f#            model_out_path =\"./model/W_epoch_{}.pth\".format(epoch)\n",
    "#            torch.save(model_W, model_out_path) actor of 0.1 every lr_decay_epoch epochs.\"\"\"\n",
    "    lr = init_lr * (0.8**(epoch // lr_decay_epoch))\n",
    "    print('LR is set to {}'.format(lr))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "# train\n",
    "pth_map = {\n",
    "    'efficientnet-b0': 'efficientnet-b0-355c32eb.pth',\n",
    "    'efficientnet-b1': 'efficientnet-b1-f1951068.pth',\n",
    "    'efficientnet-b2': 'efficientnet-b2-8bb594d6.pth',\n",
    "    'efficientnet-b3': 'efficientnet-b3-5fb5a3c3.pth',\n",
    "    'efficientnet-b4': 'efficientnet-b4-6ed6700e.pth',\n",
    "    'efficientnet-b5': 'efficientnet-b5-b6417697.pth',\n",
    "    'efficientnet-b6': 'efficientnet-b6-c76e70fd.pth',\n",
    "    'efficientnet-b7': 'efficientnet-b7-dcc49843.pth',\n",
    "}\n",
    "# 自动下载到本地预训练\n",
    "# model_ft = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "# 离线加载预训练，需要事先下载好, https://github.com/lukemelas/EfficientNet-PyTorch/releases\n",
    "model_ft = EfficientNet.from_name(net_name)\n",
    "net_weight = 'eff_weights/' + pth_map[net_name]\n",
    "state_dict = torch.load(net_weight)\n",
    "model_ft.load_state_dict(state_dict)\n",
    "\n",
    "# 修改全连接层\n",
    "num_ftrs = model_ft._fc.in_features\n",
    "model_ft._fc = nn.Linear(num_ftrs, class_num)\n",
    "\n",
    "\n",
    "\n",
    "# 109.6.19 add 下面這一行 (不加這行, 會報錯)\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    if use_gpu:\n",
    "        model_ft = model_ft.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "\n",
    "    optimizer = optim.SGD((model_ft.parameters()), lr=lr,\n",
    "                        momentum=momentum, weight_decay=0.0004)\n",
    "\n",
    "\n",
    "    train_loss, best_model_wts = train_model(model_ft, criterion, optimizer, exp_lr_scheduler, num_epochs=num_epochs)\n",
    "\n",
    "\n",
    "    # test\n",
    "    print('-' * 10)\n",
    "    print('Test Accuracy:')\n",
    "    model_ft.load_state_dict(best_model_wts)\n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "    test_model(model_ft, criterion)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
